[[{"l":"neurocircuit","p":["Neurocircuit is a tiny collection of Pytorch utilities to make your code smarter. We started to develop this library since 2023."]},{"l":"Installation","p":["Currently, we support installation from our GitHub repository."]},{"l":"Versions","p":["Metric/Loss Monitor (Automatically logging to SaaS, with Python decolator syntax)","Dataset Utility (flexible input/output formats based on Pandas Dataframe)","Parameter Autofilling (with the help of Python contextvars)","Several nice features (Early stopping, Calculating model correlation etc...)","Some tricks to avoid code clones"]}],[{"l":"Getting Started"},{"l":"Examples","p":["See our Jupyter Notebook example."]}],[{"l":"DataPipe"},{"l":"Overview","p":["In machine learning, dataset management is important since we take numerous tasks into consideration with single dataset. Let's see our entire example.","Our DataPipe works with Pandas' Dataframe, since it's easy to handle each task which differs from other tasks in terms of input/output formats.","All you have to do with DataPipe is below:","Specify inputs and targets of your Dataframe","Apply settings (such as transformations) to training/inference phase","Store your parameters (such as category size) to DataPipe","Create and select bunches of DataPipe"]},{"l":"Usage","p":["All instance methods returns an instance of itself so that you can chain those methods."]},{"i":"datapipe-1","l":"DataPipe()","p":["Create a pipeline that can see the given dataframe.","Variable","Type","Details","df","Dataframe","An object of Dataframe"]},{"i":"datapipex","l":"DataPipe.X()","p":["Add an information of model's input.","Variable","Type","Details","column","str","The column name of dataframe","data_type","Category","The column type of dataframe","* args, ** kwargs","arguments of Category object"]},{"i":"datapipey","l":"DataPipe.Y()","p":["Add an information of model's output.","Variable","Type","Details","column","str","The column name of dataframe","data_type","Category","The column type of Dataframe","* args, ** kwargs","Arguments of Category object"]},{"i":"datapipeargs","l":"DataPipe.args()","p":["Retrieve a parameter from the Category object which was previously added.","Variable","Type","Details","name","str","A name of constant variable","method","Category's method","A Category's method to retrieve a parameter from"]},{"i":"datapipebunch","l":"DataPipe.bunch()","p":["Create a bunch of the dataset in this pipeline.","Variable","Type","Details","name","str","A bunch's name"]},{"i":"datapipeselect","l":"DataPipe.select()","p":["Select multiple bunches with the given indices.","Variable","Type","Details","bunch","tuple","Tuple of bunch name","idx","Tuple of indices"]},{"i":"datapipe__call__","l":"DataPipe.__call__()","p":["A number of workers","Batch size","bool","bs","Details","Drop last mini-batch.","drop_last","Get Dataloader instances from the bunches you selected.","int","num_workers","Pin memory","pin_memory","shuffle","Shuffle the dataset","Type","Variable"]},{"i":"datapipeget_args","l":"DataPipe.get_args()","p":["Get arguments stored in DataPipe."]}],[{"l":"Monitor"},{"l":"Overview","p":["Monitor is a powerful utility that enables us to log loss values, metrics in brief code. Monitor's output is like this:","Firstly, you have to import Recorder module. We also provide WandbRecorder for someone using W&B."]},{"l":"Usage"},{"i":"with-pythons-decorator","l":"With Python`s decorator","p":["Decorators such as @recorder.track_scalar and @recorder.metric can be used to track output values of decorated functions. The following code logs loss values when training or validating our model.","Then, call recorder(training=True) or recorder(training=False) using with statement. This makes sure that all values are logged at each iteration or epoch."]},{"l":"With RecorderHelper","p":["In some situations where you can't use decorator syntax, we provide RecorderHelper to notify our recorder of the values you want to log."]},{"l":"SaaS Integration"},{"l":"WandbRecorder","p":["You can use WandbRecorder for tracking your experiment.","If you want to know the details about W&B, please visit W&B documentations."]},{"i":"what-is-torch_mean","l":"What is torch_mean?","p":["torch_mean is an aggregation method of torch.Tensor. By default, you can omit torch_mean when output type is primitive one such as int or float."]}],[{"l":"Training","p":["Here is several utilities to write your training code."]},{"i":"neurocktedakfold","l":"neurockt.eda.KFold","p":["KFold strategy reduces your variance of accuracies so that it comes easier to choose the best model. KFold is an iterator which returns train/valid indices.","Variable","Type","Details","df","int","Pandas' Dataframe","n_splits","A number of folds","y_col","str","If specified, it applys scikit-learn's StratifiedKFold to your dataset.","Source Code"]},{"i":"neurocktmonitorearlystopping","l":"neurockt.monitor.EarlyStopping","p":["EarlyStopping is useful when you want to finishing training at the middle of epochs. If a better model is found, it calls hook functions that were registed by EarlyStopping.add_hook().","Variable","Type","Details","patience","int","Maximum count of patience","mode","Category","If mode=max/min, The count will be reset when current value is higher/smaller than the previous best value.","Source Code"]},{"i":"neurockttorchforward","l":"neurockt.torch.forward","p":["This function automatically deals with your data stream and returns predictions and labels. It inspects the number of model inputs so that your model feeds only inputs.","Source Code"]},{"i":"neurockttorchstack","l":"neurockt.torch.Stack","p":["This function stacks what it feeds. It is useful when calculating over all batches.","Source Code"]}],[{"l":"Low-level API"}],[{"l":"Data"},{"l":"Multiclass","p":["Create multi-class targets.","Variable","Type","Details","df","Dataframe","A column of Dataframe"]},{"l":"Multilabel","p":["Create multi-label targets.","Variable","Type","Details","df","Dataframe","A column of Dataframe"]},{"l":"Image","p":["Create image inputs.","Variable","Type","Details","df","Dataframe","A column of Dataframe","transform","Any","Image transformation","Supported types are str(path) and torch.Tensor(raw data)."]},{"l":"Merge","p":["Merge multple datasets. Use when all inputs/outputs are individually defined.","Variable","Type","Details","indices","Dataframe","Indices of dataset samples","* datasets","list","List of datasets"]}]]